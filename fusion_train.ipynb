{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working/\n!rm -rf /kaggle/working/BrainTumour_Seg\nGITHUB_TOKEN = \"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\"\nUSER = \"RC-Sho0\"\nCLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/BrainTumour_Seg.git\"\nget_ipython().system(f\"git clone -b edit {CLONE_URL}\")\n\nimport sys\nsys.path.append(\"BrainTumour_Seg\")\n\nimport BrainTumour_Seg\n\n%cd /kaggle/working/BrainTumour_Seg\n!python /kaggle/working/BrainTumour_Seg/utils/setup.py 171b54d89f740a563652690d81f903967891a766","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:16:57.141339Z","iopub.execute_input":"2023-04-06T10:16:57.141665Z","iopub.status.idle":"2023-04-06T10:18:26.289259Z","shell.execute_reply.started":"2023-04-06T10:16:57.141633Z","shell.execute_reply":"2023-04-06T10:18:26.287938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/BrainTumour_Seg\n!python libs/data/prepare_datalist.py --path \"/kaggle/input/miccai-brats2018-original-dataset/MICCAI_BraTS_2018_Data_Training\" --output \"/kaggle/working/datalist.json\" --stage \"train\" --split 'true'","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:18:26.292092Z","iopub.execute_input":"2023-04-06T10:18:26.292510Z","iopub.status.idle":"2023-04-06T10:19:06.433020Z","shell.execute_reply.started":"2023-04-06T10:18:26.292466Z","shell.execute_reply":"2023-04-06T10:19:06.431738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/BrainTumour_Seg\nimport json\nwith open(\"/kaggle/working/datalist.json\") as f:\n    datalist = json.load(f)\n    \nfrom monai import transforms, data\nfrom libs.data.dataset import dataloader\n\n# datalist['training'] = datalist['training'] + datalist['validation']\n\ntrain_loader, val_loader = dataloader(datalist, 1, \"train\",True)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:19:06.435126Z","iopub.execute_input":"2023-04-06T10:19:06.435483Z","iopub.status.idle":"2023-04-06T10:19:12.477113Z","shell.execute_reply.started":"2023-04-06T10:19:06.435449Z","shell.execute_reply":"2023-04-06T10:19:12.475939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/BrainTumour_Seg\nfrom monai.networks.nets import DynUNet, SegResNet\nimport torch\n\ntrained = \"/kaggle/input/pretrain/results/best_metric_model.pth\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndyn = DynUNet(\n        spatial_dims=3,\n        in_channels=4,\n        out_channels=3,\n        filters = [32, 64, 128, 256, 320, 320],\n        kernel_size= [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n        strides= [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n        upsample_kernel_size=[ [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n        norm_name=\"instance\",\n        deep_supervision=False,\n        deep_supr_num=1).to(device)\ncheckpoint = torch.load(trained ,map_location=torch.device(device))\ndyn.load_state_dict(checkpoint['model'])\ndyn = dyn.to(device)\ndyn = torch.nn.Sequential(dyn.skip_layers)\ndyn.eval()\n\ntrained = \"/kaggle/input/baseline/segresnet/best_metric_model.pth\"\nseg = SegResNet(\n        blocks_down=[1, 2, 2, 4],\n        blocks_up=[1, 1, 1],\n        init_filters=16,\n        in_channels=4,\n        out_channels=3,\n        dropout_prob=0.2,).to(device)\n\ncheckpoint = torch.load(trained ,map_location=torch.device(device))\nseg.load_state_dict(checkpoint['model'])\nseg = seg.to(device)\nseg = torch.nn.Sequential(seg.act_mod, seg.convInit, *seg.down_layers, *seg.up_samples)\nseg.eval()\n\n\ndef merge(pred):\n    \n    pred = torch.squeeze(pred,0)\n    c,w,h,d = pred.shape\n    out = torch.zeros((5,w,h,d))\n    out[1] = pred[0]*2\n    out[2] = pred[1]*1\n    out[4] = pred[2]*3\n    out = torch.argmax(out,0)\n    out =  Transpose((2,1,0))(out)\n    return out\n\n\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:19:12.480096Z","iopub.execute_input":"2023-04-06T10:19:12.480391Z","iopub.status.idle":"2023-04-06T10:19:25.975628Z","shell.execute_reply.started":"2023-04-06T10:19:12.480362Z","shell.execute_reply":"2023-04-06T10:19:25.974577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.networks.blocks import Convolution\nimport torch.nn as nn\nimport torch\n\nclass TMB(nn.Module):\n    def __init__(self, in_c, mid_c):\n        super(TMB,self).__init__()\n        \n        self.prj1 = nn.Conv3d(sum(in_c), mid_c, 3, 1, 1)\n        self.prj2 = nn.Conv3d(mid_c, mid_c, 1, 1, 0)\n        self.prj3 = nn.Conv3d(mid_c, sum(in_c), 3, 1, 1)\n        \n        \n    def forward(self, x):\n        \n        x_ = self.prj1(x)\n        x_ = self.prj2(x_)\n        x_ = self.prj3(x_)\n        \n        \n        x_ = torch.mean(torch.stack([x,x_]),0)\n        return x_\n    \n    \nclass GB(nn.Module):\n    def __init__(self, num_heads = 8):\n        super(GB, self).__init__()\n        \n        self.dk = num_heads ** -0.5\n        \n    def forward(self, q, k, v):\n        \n        attn = (q @ k) * self.dk\n        attn = nn.Softmax(dim=1)(attn)\n        x = (attn @ v)\n        x = nn.Softmax(dim=1)(x)\n        x = (x * v) \n        return x + v\n\n        \n        \nclass LB(nn.Module):\n    def __init__(self, in_c, mid_c, out_c, drop=0.3):\n        super(LB, self).__init__()\n        \n        self.conv1 = nn.Conv3d(in_c, mid_c, 1, 1)\n        self.TC = nn.Conv3d(mid_c, mid_c, 3, 1, 1)\n        self.conv2 = nn.Conv3d(mid_c, out_c, 1,1)\n        self.act = nn.GELU()\n        self.drop = nn.Dropout(drop)\n        \n        \n    def forward(self, x):\n        \n        x1 = self.conv1(x)\n        x1 = self.TC(x1)\n        x1 = self.act(x1)\n        x1 = self.drop(x1)\n        x1 = self.conv2(x1)\n        x1 = self.drop(x1)\n        \n        return x1 + x\n    \n\nclass MLP(torch.nn.Module):\n    def __init__(self,in_c):\n        super(MLP, self).__init__()\n        \n        self.conv1 =Convolution(\n        spatial_dims=3,\n        in_channels=in_c,\n        out_channels=in_c,\n        strides=1, kernel_size=1,\n        adn_ordering=\"ADN\",\n            act=(\"relu\"),\n            dropout=0.1,\n            norm=(\"batch\"),\n        )\n        \n        self.conv2 =Convolution(\n        spatial_dims=3,\n        in_channels=in_c,\n        out_channels=3,\n        strides=1, kernel_size=1,\n        adn_ordering=\"ADN\",\n            act=(\"relu\"),\n            dropout=0.1,\n            norm=(\"batch\"),\n        )\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n    \nclass Fusion(nn.Module):\n    def __init__(self, in_cs, mid_c, out_c, mlp):\n        super(Fusion, self).__init__()\n\n        self.in_c1 = in_cs[0]\n        \n        self.TMB = TMB(in_cs ,mid_c)\n        \n        self.GB = GB()\n        \n        self.LB = LB(sum(in_cs), mid_c, out_c)\n        \n        self.TC1 = nn.Conv3d(in_cs[0], mid_c, 1, 1)\n        self.TC2 = nn.Conv3d(in_cs[1], mid_c, 1, 1)\n\n        self.mlp = mlp\n        \n    def forward(self, v):\n        \n        f1 = v[:,:self.in_c1,:,:,:]\n        f2 = v[:,self.in_c1:,:,:,:]\n        \n        v = torch.cat([f1,f2],1)\n        v = self.TMB(v)\n        \n        f1 = self.TC1(f1)\n        f2 = self.TC2(f2)\n        \n        v = self.GB(f1, f2, v)\n        v = self.LB(v) + v\n        v = self.mlp(v)       \n        return v\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:19:25.977039Z","iopub.execute_input":"2023-04-06T10:19:25.977935Z","iopub.status.idle":"2023-04-06T10:19:25.999134Z","shell.execute_reply.started":"2023-04-06T10:19:25.977878Z","shell.execute_reply":"2023-04-06T10:19:25.998038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.losses import DiceLoss\nfrom monai.metrics import DiceMetric\n\nmlp = MLP(48).to(device)\ncheckpoint = torch.load(\"/kaggle/input/trained-fusion/mlp/best_metric_model.pth\", map_location=torch.device(device))\nmlp.load_state_dict(checkpoint['model'])\n  \nmodel = Fusion([16,32], 48, 48, mlp).to('cuda').to(device)\ndel checkpoint\n\nloss_function = DiceLoss(smooth_nr=0, smooth_dr=5e-1, squared_pred=True, to_onehot_y=False, sigmoid=True)\n\nmetric_f = DiceMetric(include_background=True, reduction=\"mean\")\nmetric_batch_f = DiceMetric(include_background=True, reduction=\"mean_batch\")\noptimizer = torch.optim.Adam(model.parameters(), 3e-4, weight_decay=1e-4)\n\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=6)\n\nvalues = {\n    'best_metric' : -1,\n    'best_metric_epoch' : -1,\n    'best_metrics_epochs_and_time' : [[], [], []],\n    'epoch_loss_values' : [],\n    'metric_values' : [],\n    'metric_values_tc' : [],\n    'metric_values_wt' : [],\n    'metric_values_et' : [],\n}","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:19:58.430419Z","iopub.execute_input":"2023-04-06T10:19:58.430822Z","iopub.status.idle":"2023-04-06T10:19:58.457810Z","shell.execute_reply.started":"2023-04-06T10:19:58.430787Z","shell.execute_reply":"2023-04-06T10:19:58.456792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\ndef train_step(model, dyn, seg, train_loader, loss_function, optimizer, lr_scheduler, logger):\n    step, epoch_loss = 0, 0\n    for idx, inputs in enumerate(train_loader):\n            step_start = time.time()    \n            with torch.no_grad():\n                labels = inputs[\"label\"].to(device)\n                inputs = inputs[\"image\"].to(device)\n                \n                f_dyn = dyn(inputs)\n                f_seg = seg(inputs)\n\n                inputs = torch.cat((f_dyn,f_seg),1)\n                \n            x = model(inputs)\n            optimizer.zero_grad()\n            \n            loss = loss_function(x, labels)\n            \n            loss.backward()\n            optimizer.step()            \n\n            epoch_loss += loss.item()\n            print(\n                f\"{step}/{len(train_loader)}\"\n                f\", train_loss: {loss.item():.4f}\"\n                f\", step time: {(time.time() - step_start):.4f}\"\n            )\n\n            if logger:\n                logger.log({\"loss\":loss.item()})\n                \n\n            step += 1\n#             if step == 2: break\n\n    lr = optimizer.param_groups[0]['lr']\n    if logger:\n        logger.log({\"lr\":lr})\n    epoch_loss /= step\n    lr_scheduler.step(epoch_loss)\n    values['epoch_loss_values'].append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f} lr: {lr:.4f}\")\n    \n\n    \ndef val_step(model, dyn, seg, val_loader, metric_f, metric_batch_f, optimizer, config, logger):\n    model.eval()\n    post_trans = Compose([Activations(sigmoid=\"True\"), AsDiscrete(threshold=0.5)])\n    step = 0\n    with torch.no_grad():\n        for inputs in val_loader:\n            labels = inputs[\"label\"].to(device)\n            inputs = inputs[\"image\"].to(device)\n\n            f_dyn =  sliding_window_inference(inputs=inputs,  roi_size=(128, 128, 128),  sw_batch_size=1,  predictor=dyn,  overlap=0.5,)\n            f_seg =  sliding_window_inference(inputs=inputs,  roi_size=(128, 128, 128),  sw_batch_size=1,  predictor=seg,  overlap=0.5,)\n            inputs = torch.cat((f_dyn,f_seg),1)\n            x = sliding_window_inference(inputs=inputs,  roi_size=(128, 128, 128),  sw_batch_size=1,  predictor=model,  overlap=0.5,)\n            \n            val_outputs = post_trans(x)\n            metric_f(y_pred=val_outputs, y=labels)\n            metric_batch_f(y_pred=val_outputs, y=labels)\n            \n#             step += 1\n#             if step==2: break\n\n        metric = metric_f.aggregate().item()\n        values['metric_values'].append(metric)\n        metric_batch = metric_batch_f.aggregate()\n        metric_tc = metric_batch[0].item()\n        values['metric_values_tc'].append(metric_tc)\n        metric_wt = metric_batch[1].item()\n        values['metric_values_wt'].append(metric_wt)\n        metric_et = metric_batch[2].item()\n        values['metric_values_et'].append(metric_et)\n        \n        if logger:\n            logger.log({\n                \"metric_mean\": metric,\n                \"metric_wt\": metric_wt,\n                \"metric_tc\": metric_tc,\n                \"metric_et\": metric_et,\n                \"epoch\": epoch,\n                })\n        \n        metric_f.reset()\n        metric_batch_f.reset()\n\n        if metric > values['best_metric']:\n            values['best_metric'] = metric\n            values['best_metric_epoch'] = epoch + 1\n            values['best_metrics_epochs_and_time'][0].append(metric)\n            values['best_metrics_epochs_and_time'][1].append(epoch + 1)\n            values['best_metrics_epochs_and_time'][2].append(time.time() - total_start)\n            torch.save(\n                {   'epoch': epoch +1,\n                    'model': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                },\n                os.path.join(config[\"results_dir\"], \"best_metric_model.pth\"),\n            )\n            print(\"saved new best metric model\")\n        print(\n            f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n            f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n            f\"\\nbest mean dice: {values['best_metric']:.4f}\"\n            f\" at epoch: {values['best_metric_epoch']}\")\n        torch.save(\n                {   'epoch': epoch +1,\n                    'model': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                },\n                os.path.join(config[\"results_dir\"], \"last_model.pth\"),\n            )\n        print(\"saved metric model\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:19:59.202501Z","iopub.execute_input":"2023-04-06T10:19:59.204204Z","iopub.status.idle":"2023-04-06T10:19:59.237735Z","shell.execute_reply.started":"2023-04-06T10:19:59.204135Z","shell.execute_reply":"2023-04-06T10:19:59.236623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\nimport numpy as np\nimport SimpleITK as sitk\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport wandb\n\nfrom monai.data import decollate_batch\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import Compose, Activations, AsDiscrete, Transpose, Orientation, Flip\nfrom monai.losses import DiceLoss\nfrom monai.metrics import DiceMetric\n\nlogger = None\nconfig = {\n    \"name\":\"EGL_*+s\",\n    \"project\": \"fusion_att\",\n    \"results_dir\": \"/kaggle/working/\",\n    \n}\ntotal_start = time.time()\nlogger = None\nlogger = wandb.init(project=config[\"project\"], name = config[\"name\"], config=config, dir=\"/kaggle/input/pretrain/BrainTumour_Seg/\")\n\nfor epoch in range(50):\n    epoch_start = time.time()    \n    ## Train step\n   \n    train_step(model, dyn, seg, train_loader, loss_function, optimizer, lr_scheduler, logger=logger)\n    \n    ## Valid step\n        \n    if (epoch + 1) % 5  == 0:\n        val_step(model, dyn, seg, val_loader, metric_f, metric_batch_f, optimizer, config, logger= logger)\n\n    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n    total_time = time.time() - total_start\n    with open(f\"{config['results_dir']}/output.json\", \"w\") as outfile:\n        json.dump(values, outfile)\n\n    with open(f\"{config['results_dir']}/config.json\", \"w\") as outfile:\n        json.dump(config, outfile)\n\n\n    if (time.time() - total_start) > 42000:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:20:00.259421Z","iopub.execute_input":"2023-04-06T10:20:00.260135Z","iopub.status.idle":"2023-04-06T10:20:27.355042Z","shell.execute_reply.started":"2023-04-06T10:20:00.260098Z","shell.execute_reply":"2023-04-06T10:20:27.353364Z"},"trusted":true},"execution_count":null,"outputs":[]}]}